{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport PIL\nfrom PIL import Image\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"SIZE = 512\nepochs = 7\nbatch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"505ff14aa304cbe8c4e2ee69b1cc132fab71ea92"},"cell_type":"code","source":"# Load dataset info\npath_to_train = '../input/human-protein-atlas-image-classification/train/'\ndata = pd.read_csv('../input/human-protein-atlas-image-classification/train.csv')\n\ntrain_dataset_info = []\nfor name, labels in zip(data['Id'], data['Target'].str.split(' ')): \n    train_dataset_info.append({\n        'path':os.path.join(path_to_train, name),\n        'labels':np.array([int(label) for label in labels])})\ntrain_dataset_info = np.array(train_dataset_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3afcd3e29c8c5988a358cf68337afd8c33059e2d"},"cell_type":"code","source":"# Create generator\nclass data_generator:\n    \n    def create_train(dataset_info, batch_size, shape, augument=True):\n        while True:\n            dataset_info = shuffle(dataset_info)\n            for start in range(0, len(dataset_info), batch_size):\n                end = min(start + batch_size, len(dataset_info))\n                batch_images = []\n                X_train_batch = dataset_info[start:end]\n                batch_labels = np.zeros((len(X_train_batch), 28))\n                for i in range(len(X_train_batch)):\n                    image = data_generator.load_image(\n                        X_train_batch[i]['path'], shape)  \n                    if augument:\n                        image = data_generator.augment(image)\n                    batch_images.append(image/255.)\n                    batch_labels[i][X_train_batch[i]['labels']] = 1\n                yield np.array(batch_images, np.float32), batch_labels\n    \n    def load_image(path, shape):\n        image_red_ch = Image.open(path+'_red.png')\n        image_yellow_ch = Image.open(path+'_yellow.png')\n        image_green_ch = Image.open(path+'_green.png')\n        image_blue_ch = Image.open(path+'_blue.png')\n        image = np.stack((\n        np.array(image_red_ch), \n        np.array(image_green_ch), \n        np.array(image_blue_ch),\n        np.array(image_yellow_ch)), -1)\n        return image\n\n    def augment(image):\n        augment_img = iaa.Sequential([\n            iaa.OneOf([\n                iaa.Affine(rotate=0),\n                iaa.Affine(rotate=90),\n                iaa.Affine(rotate=180),\n                iaa.Affine(rotate=270),\n                iaa.Fliplr(0.5),\n                iaa.Flipud(0.5),\n            ])], random_order=True)\n        image_aug = augment_img.augment_image(image)\n        return image_aug       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1c12afd1674adb33165a649db06a780534cebeb"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split data into train, valid\nindexes = np.arange(train_dataset_info.shape[0])\nnp.random.shuffle(indexes)\ntrain_indexes, valid_indexes = train_test_split(indexes, test_size=0.15, random_state=20)\n\n# Create train and valid data generetors\ntrain_generator = data_generator.create_train(\n    train_dataset_info[train_indexes], batch_size, (SIZE, SIZE, 4), augument=True)\nvalidation_generator = data_generator.create_train(\n    train_dataset_info[valid_indexes], 32, (SIZE, SIZE, 4), augument=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f47c06290e158737bcfad418890d7635e257e9e8"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\nfrom keras.applications.xception import Xception\nfrom keras import metrics\nfrom keras.optimizers import Adam \n\n# Model    \ndef create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = Xception(include_top=False,\n                   weights='imagenet', \n                   input_shape=(253, 253, 3),\n                   pooling='avg', classes=28)\n    x = BatchNormalization()(input_tensor)\n    x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(32, kernel_size=(3,3), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(3, kernel_size=(3,3), activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = base_model(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dense(1024, activation='relu')(x)\n    output = Dense(n_out, activation='sigmoid')(x)\n    model = Model(input_tensor, output)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1858c09cbb7e7c23ca106f5e994f544b689a8fe3"},"cell_type":"code","source":"model = create_model(\n    input_shape=(SIZE, SIZE, 4), \n    n_out=28)\n    \nmodel.load_weights('../input/external-data-hpa/external_weights.h5')\n\n# Train all layers\nfor layer in model.layers:\n    layer.trainable = True\n    \nmodel.summary()\n    \nmodel.compile(loss='binary_crossentropy',\n            optimizer=Adam(lr=1e-4),\n            metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2d7658f3d66568b40f98c1e663044e5887ae95e"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\ncheckpointer = ModelCheckpoint(filepath='weights.h5', verbose=1, save_best_only=True)\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=np.ceil(float(len(train_indexes)) / float(batch_size)),\n    validation_data=validation_generator,\n    validation_steps=np.ceil(float(len(valid_indexes)) / float(batch_size)),\n    epochs=epochs, verbose=1, callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ec22559cad9adc6fc8dc299ddaf12ca9dfb3516"},"cell_type":"code","source":"# Create submit\nsubmit = pd.read_csv('../input/human-protein-atlas-image-classification/sample_submission.csv')\npredicted = []\nfor name in tqdm(submit['Id']):\n    path = os.path.join('../input/human-protein-atlas-image-classification/test/', name)\n    image = data_generator.load_image(path, (SIZE, SIZE, 4))/255.\n    score_predict = model.predict(image[np.newaxis])[0]\n    label_predict = np.arange(28)[score_predict>=0.20]\n    str_predict_label = ' '.join(str(l) for l in label_predict)\n    predicted.append(str_predict_label)\n\nsubmit['Predicted'] = predicted\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}